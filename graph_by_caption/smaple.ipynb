{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a white plate topped with a slice of cake\n",
      "[[u'plate-3', u'top with', u'slice-7'], [u'slice-7', u'of', u'cake-9']]\n",
      "[[u'plate-3', u'is', u'white']]\n",
      "a group of people riding bikes down a street \n",
      "[[u'group-2', u'of', u'people-4'], [u'people-4', u'ride', u'bike-6']]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: satoshi tsustsui\n",
    "\n",
    "Just a sample to parse caption to generate scene graph\n",
    "\n",
    "The parser reference: http://nlp.stanford.edu/software/scenegraph-parser.shtml\n",
    "This use py4j to call java from python.\n",
    "Java 1.8+ is required.\n",
    "Python 2.7x is required.\n",
    "\n",
    "You should set up parser in advance by the following command: \n",
    "java -jar SecneGraphParserPython.jar \n",
    "\n",
    "Then you can excute this file. \n",
    "'''\n",
    "\n",
    "from py4j.java_gateway import JavaGateway\n",
    "gateway = JavaGateway()\n",
    "parser = gateway.entry_point.getGraphGenerator() \n",
    "\n",
    "cap=\"a white plate topped with a slice of cake\"\n",
    "parser.parse_caption(cap)\n",
    "print cap\n",
    "print parser.get_relations()\n",
    "print parser.get_attributes()\n",
    "\n",
    "cap=\"a group of people riding bikes down a street \"\n",
    "parser.parse_caption(cap)\n",
    "print cap\n",
    "print parser.get_relations()\n",
    "print parser.get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption\n",
      "a bathroom with a toilet , sink , and mirror\n",
      "scene graph\n",
      "[[u'bathroom-2', u'with', u'toilet-5'], [u'bathroom-2', u'with', u'sink-7'], [u'bathroom-2', u'with', u'mirror-10']]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: satoshi tsustsui\n",
    "\n",
    "This is a sample code that generates scene graph from image via caption.\n",
    "Pipline will be: \n",
    "\n",
    "image -> caption -> scene_graph.\n",
    "\n",
    "image -> caption is done by https://github.com/apple2373/chainer_caption_generation/\n",
    "This git repo is also made by Satoshi Tsutsui.\n",
    "\n",
    "caption -> scene_graph is done by http://nlp.stanford.edu/software/scenegraph-parser.shtml\n",
    "This is the progeam developed by Stanford NLP lab. I call their java program by python.\n",
    "This use py4j to call java from python. Java 1.8+ and Python 2.7x is required.\n",
    "You should set up parser in advance by the following command: \n",
    "java -jar SecneGraphParserPython.jar \n",
    "\n",
    "'''\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from chainer_caption_generation.codes.image_reader import Image_reader\n",
    "from chainer_caption_generation.codes.caption_generator import Caption_generator\n",
    "\n",
    "#make sure the java commad is excuted in adcace\n",
    "from py4j.java_gateway import JavaGateway\n",
    "gateway = JavaGateway()\n",
    "parser = gateway.entry_point.getGraphGenerator() \n",
    "\n",
    "#Instantiate image_reader with GoogleNet mean image\n",
    "mean_image = np.array([104, 117, 123]).reshape((3,1,1))\n",
    "image_reader=Image_reader(mean=mean_image)\n",
    "\n",
    "#Instantiate caption generator\n",
    "caption_model_place='../chainer_caption_generation/models/caption_model.chainer'\n",
    "cnn_model_place='../chainer_caption_generation/data/bvlc_googlenet_caffe_chainer.pkl'\n",
    "index2word_place='../chainer_caption_generation/work/index2token.pkl'\n",
    "caption_generator=Caption_generator(caption_model_place=caption_model_place,cnn_model_place=cnn_model_place,index2word_place=index2word_place)\n",
    "\n",
    "#read an image as numpy arrays\n",
    "image_file_path='../chainer_caption_generation/images/COCO_val2014_000000185546.jpg'\n",
    "image=image_reader.read(image_file_path)\n",
    "caption=caption_generator.get_top_sentence(image)\n",
    "parser.parse_caption(caption)\n",
    "\n",
    "print \"caption\"\n",
    "print caption\n",
    "print \"scene graph\"\n",
    "print parser.get_relations()\n",
    "print parser.get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
